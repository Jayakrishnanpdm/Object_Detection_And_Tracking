{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayakrishnanpdm/Object_Detection_And_Tracking/blob/dev/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0c-Qp3lymCH"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypLtl4UaBIqa",
        "outputId": "c1d21c80-3d60-49bd-83a4-e33c3b578532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.2)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from insightface) (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from insightface) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from insightface) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.8)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (from insightface) (3.16.0)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.13.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (2.11.7)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (3.12.6)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (6.5.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (4.14.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2025.8.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp312-cp312-linux_x86_64.whl size=1070081 sha256=f9a68f5775f640804b69cf6a784de3c0ef3b1f16262352e40eec63dec06b9493\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/3c/e2/6d4815e8a8b33a2006554d65ce0d1f973e768f4c7a222fa675\n",
            "Successfully built insightface\n",
            "Installing collected packages: onnx, humanfriendly, coloredlogs, onnxruntime, insightface\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.7.3 onnx-1.18.0 onnxruntime-1.22.1\n"
          ]
        }
      ],
      "source": [
        "pip install insightface onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNNwJrjryqGR"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import insightface\n",
        "    from insightface.app import FaceAnalysis\n",
        "except ImportError as e:\n",
        "    print(f\"Missing InsightFace: {e}\")\n",
        "    print(\"Install with: pip install insightface onnxruntime\")\n",
        "    exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGIF5IHHyuMw"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    from IPython.display import Image as IPImage, display\n",
        "    IN_COLAB = True\n",
        "\n",
        "    # Colab webcam functionality\n",
        "    from IPython.display import Javascript\n",
        "    from google.colab.output import eval_js\n",
        "    from base64 import b64decode\n",
        "    import PIL.Image\n",
        "    import io\n",
        "\n",
        "    def take_photo(filename='photo.jpg', quality=0.8):\n",
        "        \"\"\"Take photo using Colab webcam\"\"\"\n",
        "        js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "          const div = document.createElement('div');\n",
        "          const capture = document.createElement('button');\n",
        "          capture.textContent = 'Capture';\n",
        "          div.appendChild(capture);\n",
        "\n",
        "          const video = document.createElement('video');\n",
        "          video.style.display = 'block';\n",
        "          const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "          document.body.appendChild(div);\n",
        "          div.appendChild(video);\n",
        "          video.srcObject = stream;\n",
        "          await video.play();\n",
        "\n",
        "          // Resize the output to fit the video element.\n",
        "          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "          // Wait for Capture to be clicked.\n",
        "          await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "          const canvas = document.createElement('canvas');\n",
        "          canvas.width = video.videoWidth;\n",
        "          canvas.height = video.videoHeight;\n",
        "          canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "          stream.getVideoTracks()[0].stop();\n",
        "          div.remove();\n",
        "          return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "        ''')\n",
        "        display(js)\n",
        "\n",
        "        # Get the image data\n",
        "        data = eval_js('takePhoto({})'.format(quality))\n",
        "\n",
        "        # Decode and save\n",
        "        binary = b64decode(data.split(',')[1])\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(binary)\n",
        "\n",
        "        return filename\n",
        "\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    def take_photo(filename='photo.jpg', quality=0.8):\n",
        "        print(\"‚ùå take_photo() only works in Google Colab\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXn8Qe7q7cgA"
      },
      "outputs": [],
      "source": [
        "class ColabArcFaceRecognizer:\n",
        "    \"\"\"Colab-optimized ArcFace face recognition system with enhanced confidence display\"\"\"\n",
        "\n",
        "    def __init__(self, authorized_dir='authorized', threshold=0.4, model_name='buffalo_s'):\n",
        "        self.authorized_dir = authorized_dir\n",
        "        self.threshold = threshold\n",
        "        self.model_name = model_name\n",
        "\n",
        "        # Initialize InsightFace with ArcFace\n",
        "        print(f\"üîß Loading ArcFace model: {model_name}\")\n",
        "        self.face_app = FaceAnalysis(\n",
        "            name=model_name,\n",
        "            providers=['CPUExecutionProvider']\n",
        "        )\n",
        "        self.face_app.prepare(ctx_id=-1, det_size=(640, 640))\n",
        "        print(\"‚úÖ ArcFace model loaded successfully!\")\n",
        "\n",
        "        # Storage for authorized faces\n",
        "        self.authorized_embeddings = {}\n",
        "        self.authorized_qualities = {}\n",
        "\n",
        "        # Load authorized faces\n",
        "        self.load_authorized_faces()\n",
        "\n",
        "        # Setup logging\n",
        "        logging.basicConfig(level=logging.INFO)\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def calculate_face_quality(self, face_crop):\n",
        "        \"\"\"Simple face quality assessment\"\"\"\n",
        "        try:\n",
        "            gray = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Sharpness (Laplacian variance)\n",
        "            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "\n",
        "            # Brightness\n",
        "            brightness = np.mean(gray)\n",
        "            brightness_score = 1.0 - abs(brightness - 128) / 128\n",
        "\n",
        "            # Size\n",
        "            face_size = min(face_crop.shape[:2])\n",
        "            size_score = min(face_size / 112.0, 1.0)\n",
        "\n",
        "            # Combined quality\n",
        "            quality = (\n",
        "                min(sharpness / 100.0, 1.0) * 0.4 +\n",
        "                brightness_score * 0.3 +\n",
        "                size_score * 0.3\n",
        "            )\n",
        "\n",
        "            return max(0.0, min(1.0, quality))\n",
        "        except:\n",
        "            return 0.5\n",
        "\n",
        "    def extract_all_face_embeddings(self, image):\n",
        "        \"\"\"Extract ArcFace embeddings from ALL faces in image\"\"\"\n",
        "        try:\n",
        "            faces = self.face_app.get(image)\n",
        "\n",
        "            if not faces:\n",
        "                return []\n",
        "\n",
        "            face_data = []\n",
        "            for i, face in enumerate(faces):\n",
        "                # Extract face crop for quality assessment\n",
        "                bbox = face.bbox.astype(int)\n",
        "                face_crop = image[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
        "\n",
        "                # Calculate quality\n",
        "                quality = self.calculate_face_quality(face_crop)\n",
        "\n",
        "                # Get detection confidence (if available)\n",
        "                detection_conf = getattr(face, 'det_score', 0.0)\n",
        "\n",
        "                face_data.append({\n",
        "                    'embedding': face.normed_embedding,\n",
        "                    'quality': quality,\n",
        "                    'bbox': bbox,\n",
        "                    'detection_conf': detection_conf,\n",
        "                    'face_id': i + 1\n",
        "                })\n",
        "\n",
        "            return face_data\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Embedding extraction failed: {e}\")\n",
        "            return []\n",
        "\n",
        "    def extract_face_embedding(self, image):\n",
        "        \"\"\"Extract ArcFace embedding from image with detection confidence (backward compatibility)\"\"\"\n",
        "        face_data = self.extract_all_face_embeddings(image)\n",
        "        if not face_data:\n",
        "            return None, 0.0, None, 0.0\n",
        "\n",
        "        # Return the largest face for backward compatibility\n",
        "        largest_face = max(face_data, key=lambda f: (f['bbox'][2] - f['bbox'][0]) * (f['bbox'][3] - f['bbox'][1]))\n",
        "        return largest_face['embedding'], largest_face['quality'], largest_face['bbox'], largest_face['detection_conf']\n",
        "\n",
        "    def load_authorized_faces(self):\n",
        "        \"\"\"Load authorized face images and extract embeddings\"\"\"\n",
        "        auth_path = Path(self.authorized_dir)\n",
        "        if not auth_path.exists():\n",
        "            print(f\"‚ö†Ô∏è  Authorized directory not found: {auth_path}\")\n",
        "            print(\"Creating directory...\")\n",
        "            auth_path.mkdir(exist_ok=True)\n",
        "            return\n",
        "\n",
        "        supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
        "        image_files = [f for f in auth_path.iterdir()\n",
        "                      if f.suffix.lower() in supported_formats]\n",
        "\n",
        "        if not image_files:\n",
        "            print(\"‚ö†Ô∏è  No authorized face images found!\")\n",
        "            print(f\"Please add images to: {auth_path}\")\n",
        "            return\n",
        "\n",
        "        print(f\"üìÇ Loading authorized faces from: {auth_path}\")\n",
        "        self.authorized_embeddings.clear()\n",
        "        self.authorized_qualities.clear()\n",
        "\n",
        "        for img_path in image_files:\n",
        "            try:\n",
        "                image = cv2.imread(str(img_path))\n",
        "                if image is None:\n",
        "                    print(f\"‚ùå Failed to read: {img_path.name}\")\n",
        "                    continue\n",
        "\n",
        "                embedding, quality, _, _ = self.extract_face_embedding(image)\n",
        "\n",
        "                if embedding is not None:\n",
        "                    person_name = img_path.stem\n",
        "                    self.authorized_embeddings[person_name] = embedding\n",
        "                    self.authorized_qualities[person_name] = quality\n",
        "                    print(f\"‚úÖ Loaded: {person_name} (quality: {quality:.3f})\")\n",
        "                else:\n",
        "                    print(f\"‚ùå No face found in: {img_path.name}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error loading {img_path.name}: {e}\")\n",
        "\n",
        "        print(f\"üìä Total authorized faces loaded: {len(self.authorized_embeddings)}\")\n",
        "\n",
        "    def identify_all_faces(self, image):\n",
        "        \"\"\"Identify ALL faces in image using ArcFace with detailed confidence metrics\"\"\"\n",
        "        if not self.authorized_embeddings:\n",
        "            return []\n",
        "\n",
        "        all_face_data = self.extract_all_face_embeddings(image)\n",
        "\n",
        "        if not all_face_data:\n",
        "            return []\n",
        "\n",
        "        results = []\n",
        "        for face_data in all_face_data:\n",
        "            test_embedding = face_data['embedding']\n",
        "            test_quality = face_data['quality']\n",
        "            bbox = face_data['bbox']\n",
        "            detection_conf = face_data['detection_conf']\n",
        "            face_id = face_data['face_id']\n",
        "\n",
        "            # Compare with all authorized embeddings and store all similarities\n",
        "            similarities = {}\n",
        "            best_match = None\n",
        "            best_similarity = -1.0\n",
        "\n",
        "            for name, auth_embedding in self.authorized_embeddings.items():\n",
        "                # ArcFace cosine similarity\n",
        "                similarity = np.dot(test_embedding, auth_embedding)\n",
        "                similarities[name] = similarity\n",
        "\n",
        "                if similarity > best_similarity:\n",
        "                    best_similarity = similarity\n",
        "                    best_match = name\n",
        "\n",
        "            # Quality-aware threshold adjustment\n",
        "            adjusted_threshold = self.threshold * (0.8 + 0.2 * test_quality)\n",
        "            is_authorized = best_similarity >= adjusted_threshold\n",
        "\n",
        "            results.append({\n",
        "                'face_id': face_id,\n",
        "                'is_authorized': is_authorized,\n",
        "                'best_match': best_match if is_authorized else None,\n",
        "                'quality': test_quality,\n",
        "                'similarity': best_similarity,\n",
        "                'bbox': bbox,\n",
        "                'detection_conf': detection_conf,\n",
        "                'similarities': similarities,\n",
        "                'adjusted_threshold': adjusted_threshold\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def identify_face(self, image):\n",
        "        \"\"\"Identify face in image using ArcFace with detailed confidence metrics (backward compatibility)\"\"\"\n",
        "        results = self.identify_all_faces(image)\n",
        "        if not results:\n",
        "            return False, None, 0.0, 0.0, None, 0.0, {}\n",
        "\n",
        "        # Return the result with highest similarity for backward compatibility\n",
        "        best_result = max(results, key=lambda r: r['similarity'])\n",
        "        return (best_result['is_authorized'], best_result['best_match'],\n",
        "                best_result['quality'], best_result['similarity'],\n",
        "                best_result['bbox'], best_result['detection_conf'],\n",
        "                best_result['similarities'])\n",
        "\n",
        "    def draw_enhanced_face_box(self, image, bbox, is_authorized, name, similarity, quality, detection_conf, similarities, face_id, adjusted_threshold):\n",
        "        \"\"\"Draw enhanced bounding box with detailed confidence information\"\"\"\n",
        "        x1, y1, x2, y2 = bbox.astype(int)\n",
        "\n",
        "        # Colors\n",
        "        color = (0, 255, 0) if is_authorized else (0, 0, 255)  # Green for authorized, red for unauthorized\n",
        "        bg_color = (0, 50, 0) if is_authorized else (0, 0, 50)  # Dark background for text\n",
        "\n",
        "        # Draw main bounding box with thicker border for multiple faces\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 3)\n",
        "\n",
        "        # Prepare text information\n",
        "        face_label = f\"Face #{face_id}\"\n",
        "        main_label = f\"{name if name else 'Unknown'}\"\n",
        "        similarity_text = f\"Sim: {similarity:.3f}\"\n",
        "        quality_text = f\"Qual: {quality:.3f}\"\n",
        "        detection_text = f\"Det: {detection_conf:.3f}\"\n",
        "        threshold_text = f\"Thresh: {adjusted_threshold:.3f}\"\n",
        "\n",
        "        # Calculate text dimensions\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        font_scale = 0.45\n",
        "        thickness = 1\n",
        "\n",
        "        texts = [face_label, main_label, similarity_text, quality_text, detection_text, threshold_text]\n",
        "        text_heights = []\n",
        "        text_widths = []\n",
        "\n",
        "        for text in texts:\n",
        "            (w, h), _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
        "            text_widths.append(w)\n",
        "            text_heights.append(h)\n",
        "\n",
        "        max_width = max(text_widths)\n",
        "        total_height = sum(text_heights) + len(texts) * 4  # 4px padding between lines\n",
        "\n",
        "        # Calculate text position to avoid overlap with other faces\n",
        "        text_bg_x1 = x1\n",
        "        text_bg_y1 = y1 - total_height - 10\n",
        "        text_bg_x2 = x1 + max_width + 10\n",
        "        text_bg_y2 = y1\n",
        "\n",
        "        # Adjust if text goes above image boundary\n",
        "        if text_bg_y1 < 0:\n",
        "            text_bg_y1 = y2 + 5\n",
        "            text_bg_y2 = y2 + total_height + 15\n",
        "\n",
        "        # Ensure text doesn't go beyond image boundaries\n",
        "        img_height, img_width = image.shape[:2]\n",
        "        if text_bg_x2 > img_width:\n",
        "            text_bg_x1 = x2 - max_width - 10\n",
        "            text_bg_x2 = x2\n",
        "\n",
        "        if text_bg_y2 > img_height:\n",
        "            text_bg_y1 = y1 - total_height - 10\n",
        "            text_bg_y2 = y1\n",
        "\n",
        "        cv2.rectangle(image, (text_bg_x1, text_bg_y1), (text_bg_x2, text_bg_y2), bg_color, -1)\n",
        "        cv2.rectangle(image, (text_bg_x1, text_bg_y1), (text_bg_x2, text_bg_y2), color, 1)\n",
        "\n",
        "        # Draw text lines\n",
        "        current_y = text_bg_y1 + text_heights[0] + 4\n",
        "\n",
        "        for i, text in enumerate(texts):\n",
        "            # Use different colors for different types of information\n",
        "            if i == 0:  # Face ID\n",
        "                text_color = (255, 255, 255)  # White\n",
        "            elif i == 1:  # Name\n",
        "                text_color = (255, 255, 255)  # White\n",
        "            elif i == 2:  # Similarity\n",
        "                text_color = (0, 255, 255) if similarity >= adjusted_threshold else (0, 100, 255)  # Cyan or orange\n",
        "            elif i == 3:  # Quality\n",
        "                text_color = (255, 255, 0)  # Yellow\n",
        "            elif i == 4:  # Detection confidence\n",
        "                text_color = (255, 0, 255)  # Magenta\n",
        "            else:  # Threshold\n",
        "                text_color = (200, 200, 200)  # Light gray\n",
        "\n",
        "            cv2.putText(image, text, (text_bg_x1 + 5, current_y), font, font_scale, text_color, thickness)\n",
        "\n",
        "            if i < len(texts) - 1:\n",
        "                current_y += max(text_heights) + 4\n",
        "\n",
        "        # Draw confidence bar\n",
        "        bar_width = x2 - x1\n",
        "        bar_height = 6\n",
        "        bar_x = x1\n",
        "        bar_y = y2 + 8\n",
        "\n",
        "        # Ensure bar doesn't go beyond image\n",
        "        if bar_y + bar_height < img_height:\n",
        "            # Background bar\n",
        "            cv2.rectangle(image, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (100, 100, 100), -1)\n",
        "\n",
        "            # Confidence bar (based on similarity score)\n",
        "            confidence_width = int(bar_width * min(similarity, 1.0))\n",
        "            bar_color = (0, 255, 0) if is_authorized else (0, 0, 255)\n",
        "            cv2.rectangle(image, (bar_x, bar_y), (bar_x + confidence_width, bar_y + bar_height), bar_color, -1)\n",
        "\n",
        "            # Threshold line\n",
        "            threshold_x = bar_x + int(bar_width * adjusted_threshold)\n",
        "            cv2.line(image, (threshold_x, bar_y), (threshold_x, bar_y + bar_height), (255, 255, 255), 2)\n",
        "\n",
        "        return image\n",
        "\n",
        "    def take_photo_and_test(self):\n",
        "        \"\"\"Take photo using Colab webcam and test recognition\"\"\"\n",
        "        if not IN_COLAB:\n",
        "            print(\"‚ùå Webcam capture only works in Google Colab\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            print(\"üì∑ Taking photo using webcam...\")\n",
        "            filename = take_photo('captured_photo.jpg')\n",
        "            print(f'‚úÖ Photo saved to {filename}')\n",
        "\n",
        "            # Display the captured photo\n",
        "            print(\"üì∏ Captured photo:\")\n",
        "            display(IPImage(filename))\n",
        "\n",
        "            # Test face recognition on the captured photo\n",
        "            print(\"\\nüîç Running face recognition...\")\n",
        "            self.test_single_image(filename)\n",
        "\n",
        "            # Clean up\n",
        "            os.remove(filename)\n",
        "\n",
        "        except Exception as err:\n",
        "            print(f\"‚ùå Error taking photo: {str(err)}\")\n",
        "            print(\"Make sure to grant camera permissions when prompted.\")\n",
        "\n",
        "    def capture_authorized_face(self):\n",
        "        \"\"\"Capture a new authorized face using webcam\"\"\"\n",
        "        if not IN_COLAB:\n",
        "            print(\"‚ùå Webcam capture only works in Google Colab\")\n",
        "            return\n",
        "\n",
        "        person_name = input(\"Enter person's name for authorization: \").strip()\n",
        "        if not person_name:\n",
        "            print(\"‚ùå Name cannot be empty\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            print(f\"üì∑ Taking photo for authorized person: {person_name}\")\n",
        "            filename = take_photo('temp_auth_photo.jpg')\n",
        "            print(f'‚úÖ Photo captured')\n",
        "\n",
        "            # Display the captured photo\n",
        "            print(\"üì∏ Captured photo:\")\n",
        "            display(IPImage(filename))\n",
        "\n",
        "            # Ask for confirmation\n",
        "            confirm = input(\"Use this photo for authorization? (y/n): \").lower()\n",
        "            if confirm == 'y':\n",
        "                # Move to authorized directory with proper name\n",
        "                auth_filename = f\"{self.authorized_dir}/{person_name}.jpg\"\n",
        "                os.rename(filename, auth_filename)\n",
        "                print(f\"‚úÖ Saved authorized face: {auth_filename}\")\n",
        "\n",
        "                # Reload authorized faces\n",
        "                self.load_authorized_faces()\n",
        "            else:\n",
        "                os.remove(filename)\n",
        "                print(\"‚ùå Photo discarded\")\n",
        "\n",
        "        except Exception as err:\n",
        "            print(f\"‚ùå Error capturing authorized face: {str(err)}\")\n",
        "            print(\"Make sure to grant camera permissions when prompted.\")\n",
        "\n",
        "    def test_from_url(self, image_url):\n",
        "        \"\"\"Test recognition from image URL\"\"\"\n",
        "        try:\n",
        "            print(f\"üì• Downloading image from URL...\")\n",
        "            response = requests.get(image_url)\n",
        "\n",
        "            # Convert to OpenCV format\n",
        "            pil_image = Image.open(BytesIO(response.content))\n",
        "            cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            print(f\"üîç Testing downloaded image...\")\n",
        "            self.test_image_array(cv_image, \"Downloaded Image\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error downloading/testing image: {e}\")\n",
        "\n",
        "    def test_single_image(self, image_path):\n",
        "        \"\"\"Test recognition on a single image file\"\"\"\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"‚ùå Cannot read image: {image_path}\")\n",
        "            return\n",
        "\n",
        "        self.test_image_array(image, image_path)\n",
        "\n",
        "    def test_image_array(self, image, image_name=\"Test Image\"):\n",
        "        \"\"\"Test recognition on image array with enhanced visualization for ALL faces\"\"\"\n",
        "        print(f\"üîç Testing: {image_name}\")\n",
        "\n",
        "        # Get results for ALL faces\n",
        "        all_face_results = self.identify_all_faces(image)\n",
        "\n",
        "        if not all_face_results:\n",
        "            print(\"‚ùå No faces detected in the image\")\n",
        "            result_image = image.copy()\n",
        "            cv2.putText(result_image, \"No faces detected\", (10, 30),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        else:\n",
        "            print(f\"üë• Found {len(all_face_results)} face(s) in the image\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "            # Create enhanced visualization\n",
        "            result_image = image.copy()\n",
        "\n",
        "            # Process each face\n",
        "            for i, face_result in enumerate(all_face_results):\n",
        "                face_id = face_result['face_id']\n",
        "                is_auth = face_result['is_authorized']\n",
        "                name = face_result['best_match']\n",
        "                quality = face_result['quality']\n",
        "                similarity = face_result['similarity']\n",
        "                bbox = face_result['bbox']\n",
        "                detection_conf = face_result['detection_conf']\n",
        "                similarities = face_result['similarities']\n",
        "                adjusted_threshold = face_result['adjusted_threshold']\n",
        "\n",
        "                print(f\"üìä Face #{face_id} Results:\")\n",
        "                print(f\"   Authorized: {'‚úÖ YES' if is_auth else '‚ùå NO'}\")\n",
        "                print(f\"   Best Match: {name if name else 'Unknown'}\")\n",
        "                print(f\"   Face Quality: {quality:.3f}\")\n",
        "                print(f\"   Similarity Score: {similarity:.3f}\")\n",
        "                print(f\"   Detection Confidence: {detection_conf:.3f}\")\n",
        "                print(f\"   Base Threshold: {self.threshold}\")\n",
        "                print(f\"   Quality-Adjusted Threshold: {adjusted_threshold:.3f}\")\n",
        "                print(f\"   Face Location: ({bbox[0]:.0f}, {bbox[1]:.0f}) to ({bbox[2]:.0f}, {bbox[3]:.0f})\")\n",
        "\n",
        "                # Show all similarity scores for this face\n",
        "                if similarities:\n",
        "                    print(f\"   All Similarity Scores:\")\n",
        "                    sorted_sims = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
        "                    for person, sim in sorted_sims:\n",
        "                        status = \"‚úÖ\" if sim >= adjusted_threshold else \"‚ùå\"\n",
        "                        print(f\"     {status} {person}: {sim:.3f}\")\n",
        "\n",
        "                # Draw enhanced visualization for this face\n",
        "                result_image = self.draw_enhanced_face_box(\n",
        "                    result_image, bbox, is_auth, name, similarity,\n",
        "                    quality, detection_conf, similarities, face_id, adjusted_threshold\n",
        "                )\n",
        "\n",
        "                if i < len(all_face_results) - 1:\n",
        "                    print(\"-\" * 40)\n",
        "\n",
        "            # Summary statistics\n",
        "            authorized_count = sum(1 for result in all_face_results if result['is_authorized'])\n",
        "            print(\"=\" * 60)\n",
        "            print(f\"üìà Summary: {authorized_count}/{len(all_face_results)} faces authorized\")\n",
        "            print(f\"   Authorized faces: {authorized_count}\")\n",
        "            print(f\"   Unauthorized faces: {len(all_face_results) - authorized_count}\")\n",
        "\n",
        "            # Add summary text to image\n",
        "            summary_text = f\"Faces: {len(all_face_results)} | Authorized: {authorized_count}\"\n",
        "            cv2.putText(result_image, summary_text, (10, 30),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "            cv2.putText(result_image, summary_text, (10, 30),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)  # Black outline\n",
        "\n",
        "        # Save result\n",
        "        result_filename = f\"recognition_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
        "        cv2.imwrite(result_filename, result_image)\n",
        "        print(f\"üíæ Enhanced result saved as: {result_filename}\")\n",
        "\n",
        "        # Display in Colab\n",
        "        if IN_COLAB:\n",
        "            print(\"üì∏ Enhanced Recognition Result:\")\n",
        "            display(IPImage(result_filename))\n",
        "\n",
        "    def upload_and_test(self):\n",
        "        \"\"\"Upload image and test recognition (Colab-friendly)\"\"\"\n",
        "        if not IN_COLAB:\n",
        "            print(\"‚ùå This feature requires Google Colab\")\n",
        "            return\n",
        "\n",
        "        print(\"üì§ Upload an image to test face recognition:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            self.test_single_image(filename)\n",
        "            # Clean up\n",
        "            os.remove(filename)\n",
        "\n",
        "    def batch_test_directory(self, test_dir):\n",
        "        \"\"\"Test all images in a directory with multi-face support\"\"\"\n",
        "        test_path = Path(test_dir)\n",
        "        if not test_path.exists():\n",
        "            print(f\"‚ùå Test directory not found: {test_dir}\")\n",
        "            return\n",
        "\n",
        "        supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
        "        image_files = [f for f in test_path.iterdir()\n",
        "                      if f.suffix.lower() in supported_formats]\n",
        "\n",
        "        if not image_files:\n",
        "            print(f\"‚ùå No images found in: {test_dir}\")\n",
        "            return\n",
        "\n",
        "        print(f\"üîç Testing {len(image_files)} images from: {test_dir}\")\n",
        "\n",
        "        all_results = []\n",
        "        total_faces = 0\n",
        "        total_authorized = 0\n",
        "\n",
        "        for img_path in image_files:\n",
        "            image = cv2.imread(str(img_path))\n",
        "            if image is not None:\n",
        "                face_results = self.identify_all_faces(image)\n",
        "                if face_results:\n",
        "                    authorized_faces = sum(1 for result in face_results if result['is_authorized'])\n",
        "                    total_faces += len(face_results)\n",
        "                    total_authorized += authorized_faces\n",
        "\n",
        "                    print(f\"   üìÅ {img_path.name}: {len(face_results)} face(s), {authorized_faces} authorized\")\n",
        "\n",
        "                    for face_result in face_results:\n",
        "                        all_results.append({\n",
        "                            'filename': img_path.name,\n",
        "                            'face_id': face_result['face_id'],\n",
        "                            'authorized': face_result['is_authorized'],\n",
        "                            'match': face_result['best_match'],\n",
        "                            'quality': face_result['quality'],\n",
        "                            'similarity': face_result['similarity'],\n",
        "                            'detection_confidence': face_result['detection_conf'],\n",
        "                            'all_similarities': face_result['similarities']\n",
        "                        })\n",
        "                else:\n",
        "                    print(f\"   üìÅ {img_path.name}: No faces detected\")\n",
        "\n",
        "        print(f\"\\nüìä Batch Test Summary:\")\n",
        "        print(f\"   Total images processed: {len(image_files)}\")\n",
        "        print(f\"   Total faces detected: {total_faces}\")\n",
        "        print(f\"   Total authorized faces: {total_authorized}\")\n",
        "        print(f\"   Authorization rate: {(total_authorized/total_faces*100):.1f}%\" if total_faces > 0 else \"   Authorization rate: N/A\")\n",
        "\n",
        "        return all_results\n",
        "\n",
        "    def interactive_menu(self):\n",
        "        \"\"\"Interactive menu for Colab\"\"\"\n",
        "        while True:\n",
        "            print(\"\\nüéÆ Enhanced Colab ArcFace Recognition Menu:\")\n",
        "            print(\"1. üì∑ Take photo and test (Webcam)\")\n",
        "            print(\"2. üì§ Upload and test image\")\n",
        "            print(\"3. üåê Test image from URL\")\n",
        "            print(\"4. üë§ Capture authorized face (Webcam)\")\n",
        "            print(\"5. üìÅ Upload authorized faces\")\n",
        "            print(\"6. üîÑ Reload authorized faces\")\n",
        "            print(\"7. ‚ÑπÔ∏è  Show system info\")\n",
        "            print(\"8. ‚öôÔ∏è  Adjust threshold\")\n",
        "            print(\"9. ‚ùå Quit\")\n",
        "\n",
        "            try:\n",
        "                choice = input(\"\\nEnter choice (1-9): \").strip()\n",
        "\n",
        "                if choice == '1':\n",
        "                    self.take_photo_and_test()\n",
        "\n",
        "                elif choice == '2':\n",
        "                    self.upload_and_test()\n",
        "\n",
        "                elif choice == '3':\n",
        "                    url = input(\"Enter image URL: \").strip()\n",
        "                    if url:\n",
        "                        self.test_from_url(url)\n",
        "\n",
        "                elif choice == '4':\n",
        "                    self.capture_authorized_face()\n",
        "\n",
        "                elif choice == '5':\n",
        "                    self.upload_authorized_faces()\n",
        "\n",
        "                elif choice == '6':\n",
        "                    self.load_authorized_faces()\n",
        "\n",
        "                elif choice == '7':\n",
        "                    self.show_system_info()\n",
        "\n",
        "                elif choice == '8':\n",
        "                    new_threshold = float(input(f\"Current threshold: {self.threshold}. Enter new threshold (0.0-1.0): \"))\n",
        "                    if 0.0 <= new_threshold <= 1.0:\n",
        "                        self.threshold = new_threshold\n",
        "                        print(f\"‚úÖ Threshold updated to: {self.threshold}\")\n",
        "                    else:\n",
        "                        print(\"‚ùå Invalid threshold! Must be between 0.0 and 1.0\")\n",
        "\n",
        "                elif choice == '9':\n",
        "                    print(\"üëã Goodbye!\")\n",
        "                    break\n",
        "\n",
        "                else:\n",
        "                    print(\"‚ùå Invalid choice!\")\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\nüëã Goodbye!\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "    def upload_authorized_faces(self):\n",
        "        \"\"\"Upload new authorized face images\"\"\"\n",
        "        if not IN_COLAB:\n",
        "            print(\"‚ùå This feature requires Google Colab\")\n",
        "            return\n",
        "\n",
        "        print(\"üì§ Upload authorized face images:\")\n",
        "        print(\"Tip: Name files like 'john_doe.jpg', 'jane_smith.png'\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            new_path = f\"{self.authorized_dir}/{filename}\"\n",
        "            os.rename(filename, new_path)\n",
        "            person_name = os.path.splitext(filename)[0]\n",
        "            print(f\"‚úÖ Added authorized face: {person_name}\")\n",
        "\n",
        "        # Reload faces\n",
        "        self.load_authorized_faces()\n",
        "\n",
        "    def show_system_info(self):\n",
        "        \"\"\"Display system information\"\"\"\n",
        "        print(f\"\\nüìä Enhanced ArcFace Recognition System Info:\")\n",
        "        print(f\"   Model: {self.model_name}\")\n",
        "        print(f\"   Recognition Threshold: {self.threshold}\")\n",
        "        print(f\"   Authorized Faces: {len(self.authorized_embeddings)}\")\n",
        "        print(f\"   Environment: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "        print(f\"   Enhanced Features: ‚úÖ Confidence Scores, Quality Assessment, Multi-match Display\")\n",
        "\n",
        "        if self.authorized_embeddings:\n",
        "            print(f\"\\nüë• Authorized Personnel:\")\n",
        "            for name, quality in self.authorized_qualities.items():\n",
        "                print(f\"     ‚Ä¢ {name}: quality {quality:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O3nC1njzJF2"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"Main function optimized for Colab with enhanced confidence display\"\"\"\n",
        "    print(\"ü§ñ Enhanced Colab-Friendly ArcFace Face Recognition\")\n",
        "    print(\"‚ú® Now with detailed confidence scores and visualization!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize recognizer with faster model for Colab\n",
        "    recognizer = ColabArcFaceRecognizer(\n",
        "        authorized_dir='authorized',\n",
        "        threshold=0.4,\n",
        "        model_name='buffalo_s'  # Faster model for Colab\n",
        "    )\n",
        "\n",
        "    if len(recognizer.authorized_embeddings) == 0:\n",
        "        print(\"\\n‚ö†Ô∏è  No authorized faces found!\")\n",
        "        print(\"Choose option 5 to upload authorized face images.\")\n",
        "\n",
        "    # Start interactive menu\n",
        "    recognizer.interactive_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjpxRyEhzQSR",
        "outputId": "f7280403-740a-462c-ada7-94fbe1fcecc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Enhanced Colab-Friendly ArcFace Face Recognition\n",
            "‚ú® Now with detailed confidence scores and visualization!\n",
            "============================================================\n",
            "üîß Loading ArcFace model: buffalo_s\n",
            "download_path: /root/.insightface/models/buffalo_s\n",
            "Downloading /root/.insightface/models/buffalo_s.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_s.zip...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 124617/124617 [00:02<00:00, 60935.56KB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_s/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_s/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_s/det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_s/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_s/w600k_mbf.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "‚úÖ ArcFace model loaded successfully!\n",
            "‚ö†Ô∏è  Authorized directory not found: authorized\n",
            "Creating directory...\n",
            "\n",
            "‚ö†Ô∏è  No authorized faces found!\n",
            "Choose option 5 to upload authorized face images.\n",
            "\n",
            "üéÆ Enhanced Colab ArcFace Recognition Menu:\n",
            "1. üì∑ Take photo and test (Webcam)\n",
            "2. üì§ Upload and test image\n",
            "3. üåê Test image from URL\n",
            "4. üë§ Capture authorized face (Webcam)\n",
            "5. üìÅ Upload authorized faces\n",
            "6. üîÑ Reload authorized faces\n",
            "7. ‚ÑπÔ∏è  Show system info\n",
            "8. ‚öôÔ∏è  Adjust threshold\n",
            "9. ‚ùå Quit\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45da7278"
      },
      "source": [
        "# Task\n",
        "Resolve dependency conflicts related to numpy by uninstalling mediapipe and removing related code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34f29626"
      },
      "source": [
        "## Uninstall mediapipe\n",
        "\n",
        "### Subtask:\n",
        "Remove mediapipe to eliminate its dependency on an older numpy version.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40ea5194"
      },
      "source": [
        "**Reasoning**:\n",
        "Uninstall mediapipe to resolve the numpy dependency conflict.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e48356e2"
      },
      "source": [
        "## Remove hand detection code\n",
        "\n",
        "### Subtask:\n",
        "Delete or comment out the code related to mediapipe hand detection in the `ObjectTracker` class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a9f1f6b"
      },
      "source": [
        "**Reasoning**:\n",
        "Comment out or delete the code related to mediapipe hand detection in the ObjectTracker class, which includes the initialization in `setup_models` and the entire `detect_hands` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23ee3a0c"
      },
      "source": [
        "**Reasoning**:\n",
        "Continue by commenting out or deleting the line that calls `self.object_tracker.detect_hands(frame)` in the `analyze_interactions` method and the code block that iterates through `hand_bboxes` and draws rectangles and labels for hands in the `draw_overlays` method within the `InteractionMonitor` class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6530fdf"
      },
      "source": [
        "## Remove mediapipe import\n",
        "\n",
        "### Subtask:\n",
        "Remove the mediapipe import statement from the code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cd541c0"
      },
      "source": [
        "**Reasoning**:\n",
        "Remove the mediapipe import statement from the code block where it is imported along with other libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2910249"
      },
      "source": [
        "## Update dependencies list\n",
        "\n",
        "### Subtask:\n",
        "Update the pip install command to reflect the removal of mediapipe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3321e7c4"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps removed the mediapipe dependency and related code. Now, the pip install command that installs computer vision packages needs to be updated to remove 'mediapipe' from the list of packages to be installed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d9daa0d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The `mediapipe` package version 0.10.21 was successfully uninstalled.\n",
        "*   All code references to `mediapipe.solutions.hands`, including initialization, the detection method, and calls to it, were commented out or deleted from the `ObjectTracker` and `InteractionMonitor` classes.\n",
        "*   The `mediapipe` import statement was commented out from the main import block.\n",
        "*   The `!pip install` command in the notebook was updated to remove `mediapipe` from the list of packages to be installed.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The removal of `mediapipe` and its associated code resolves the dependency conflict with `numpy`.\n",
        "*   The system's hand detection functionality has been removed and would need an alternative implementation if required in the future.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fd97814"
      },
      "source": [
        "## Uninstall mediapipe\n",
        "\n",
        "### Subtask:\n",
        "Remove mediapipe to eliminate its dependency on an older numpy version."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f75ff95d"
      },
      "source": [
        "**Reasoning**:\n",
        "Uninstall mediapipe to resolve the numpy dependency conflict."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}